{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58913c9-f058-45d9-aaa1-cab8f30294d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "# creating time frame\n",
    "years = list(range(2000, 2024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "702c3511-d8b9-4979-9ae4-81f025a284c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro football reference mvp voting template url\n",
    "url_start = \"https://www.pro-football-reference.com/awards/awards_{}.htm#voting_apmvp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abf53e7-e6a2-49ce-9c68-9b026a56ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping mvp votes for all years in time frame\n",
    "for year in years:\n",
    "    url = url_start.format(year)\n",
    "    data = requests.get(url)\n",
    "\n",
    "    with open(\"mvps/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(data.text)\n",
    "\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "767c774c-2b4b-41e2-9c26-f48d8f60a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing vote tables\n",
    "dfs = []\n",
    "for year in years:\n",
    "    with open(\"mvps/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    soup.find('tr', class_=\"over_header\").decompose() # removing extra header\n",
    "    mvp_table = soup.find(id=\"voting_apmvp\")\n",
    "    mvp_df = pd.read_html(StringIO(str(mvp_table)))[0]\n",
    "    mvp_df[\"Year\"] = year\n",
    "\n",
    "    dfs.append(mvp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27315743-a0e9-4e0e-a448-3d90cdccfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mvps = pd.concat(dfs)\n",
    "mvps.to_csv(\"mvps.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f59c1cc-526f-46ed-8925-444d97c1bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro football reference mvp player stats template url\n",
    "passing_stats_url = \"https://www.pro-football-reference.com/years/{}/passing.htm\"\n",
    "receiving_stats_url = \"https://www.pro-football-reference.com/years/{}/receiving.htm\"\n",
    "rushing_stats_url = \"https://www.pro-football-reference.com/years/{}/rushing.htm\"\n",
    "# scrimmage_stats_url = \"https://www.pro-football-reference.com/years/{}/scrimmage.htm\"\n",
    "defense_stats_url = \"https://www.pro-football-reference.com/years/{}/defense.htm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "438a5768-46ed-4780-9be1-98e7130b5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping player stats for all years in time frame\n",
    "for year in years:\n",
    "    url = passing_stats_url.format(year)\n",
    "    data = requests.get(url)\n",
    "\n",
    "    with open(\"passing/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(data.text)\n",
    "\n",
    "    time.sleep(15)\n",
    "\n",
    "for year in years:\n",
    "    url = receiving_stats_url.format(year)\n",
    "    data = requests.get(url)\n",
    "\n",
    "    with open(\"receiving/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(data.text)\n",
    "\n",
    "    time.sleep(15)\n",
    "\n",
    "for year in years:\n",
    "    url = rushing_stats_url.format(year)\n",
    "    data = requests.get(url)\n",
    "\n",
    "    with open(\"rushing/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(data.text)\n",
    "\n",
    "    time.sleep(15)\n",
    "\n",
    "# for year in years:\n",
    "#     url = scrimmage_stats_url.format(year)\n",
    "#     data = requests.get(url)\n",
    "\n",
    "#     with open(\"scrimmage/{}.html\".format(year), \"w+\") as f:\n",
    "#         f.write(data.text)\n",
    "\n",
    "#     time.sleep(15)\n",
    "\n",
    "for year in years:\n",
    "    url = defense_stats_url.format(year)\n",
    "    data = requests.get(url)\n",
    "\n",
    "    with open(\"defense/{}.html\".format(year), \"w+\") as f:\n",
    "        f.write(data.text)\n",
    "\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1f4327-f376-4dc3-a8ac-540f23029768",
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(executable_path=\"/Users/benja/Desktop/Projects/chromedriver.exe\")\n",
    "options = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "038beed3-e931-40a2-ae86-021500259eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "    url = passing_stats_url.format(year)\n",
    "\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(1, 10000)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    with open(\"passing/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "for year in years:\n",
    "    url = receiving_stats_url.format(year)\n",
    "\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(1, 10000)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    with open(\"receiving/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "for year in years:\n",
    "    url = rushing_stats_url.format(year)\n",
    "\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(1, 10000)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    with open(\"rushing/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "\n",
    "# for year in years:\n",
    "#     url = scrimmage_stats_url.format(year)\n",
    "\n",
    "#     driver.get(url)\n",
    "#     driver.execute_script(\"window.scrollTo(1, 10000)\")\n",
    "#     time.sleep(2)\n",
    "\n",
    "#     html = driver.page_source\n",
    "#     with open(\"scrimmage/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "#         f.write(html)\n",
    "\n",
    "for year in years:\n",
    "    url = defense_stats_url.format(year)\n",
    "\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(1, 10000)\")\n",
    "    time.sleep(2)\n",
    "\n",
    "    html = driver.page_source\n",
    "    with open(\"defense/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf4c346-6668-4b47-9f9d-58fe1cdcf170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing player data\n",
    "passing_dfs = []\n",
    "for year in years:\n",
    "    with open(\"passing/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    header_rows = soup.find_all('tr', class_='thead')\n",
    "    for header_row in header_rows:\n",
    "        header_row.decompose()\n",
    "    passing_table = soup.find(id=\"passing\")\n",
    "    passing_df = pd.read_html(StringIO(str(passing_table)))[0]\n",
    "    passing_df[\"Year\"] = year\n",
    "\n",
    "    passing_dfs.append(passing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "32388eb0-8b64-45da-9eb4-a2e30ce1b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving_dfs = []\n",
    "for year in years:\n",
    "    with open(\"receiving/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    header_rows = soup.find_all('tr', class_='thead')\n",
    "    for header_row in header_rows:\n",
    "        header_row.decompose()\n",
    "    receiving_table = soup.find(id=\"receiving\")\n",
    "    receiving_df = pd.read_html(StringIO(str(receiving_table)))[0]\n",
    "    receiving_df[\"Year\"] = year\n",
    "\n",
    "    receiving_dfs.append(receiving_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91d196bf-d202-4cdd-ac9e-4611bc6cecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rushing_dfs = []\n",
    "for year in years:\n",
    "    with open(\"rushing/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    soup.find('tr', class_=\"over_header\").decompose()\n",
    "    header_rows = soup.find_all('tr', class_='thead')\n",
    "    for header_row in header_rows:\n",
    "        header_row.decompose()\n",
    "    rushing_table = soup.find(id=\"rushing\")\n",
    "    rushing_df = pd.read_html(StringIO(str(rushing_table)))[0]\n",
    "    rushing_df[\"Year\"] = year\n",
    "\n",
    "    rushing_dfs.append(rushing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9cfdb4e2-dab1-43ac-9f6f-7ae3ed66944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrimmage_dfs = []\n",
    "# for year in years:\n",
    "#     with open(\"scrimmage/{}.html\".format(year)) as f:\n",
    "#         page = f.read()\n",
    "\n",
    "#     soup = BeautifulSoup(page, 'html.parser')\n",
    "#     soup.find('tr', class_=\"over_header\").decompose()\n",
    "#     header_rows = soup.find_all('tr', class_='thead')\n",
    "#     for header_row in header_rows:\n",
    "#         header_row.decompose()\n",
    "#     scrimmage_table = soup.find(id=\"receiving_and_rushing\")\n",
    "#     scrimmage_df = pd.read_html(StringIO(str(scrimmage_table)))[0]\n",
    "#     scrimmage_df[\"Year\"] = year\n",
    "\n",
    "#     scrimmage_dfs.append(scrimmage_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1a82f906-7c42-4cf4-9115-2833d2993870",
   "metadata": {},
   "outputs": [],
   "source": [
    "defense_dfs = []\n",
    "for year in years:\n",
    "    with open(\"defense/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    soup.find('tr', class_=\"over_header\").decompose() \n",
    "    header_rows = soup.find_all('tr', class_='thead')\n",
    "    for header_row in header_rows:\n",
    "        header_row.decompose()\n",
    "    defense_table = soup.find(id=\"defense\")\n",
    "    defense_df = pd.read_html(StringIO(str(defense_table)))[0]\n",
    "    defense_df[\"Year\"] = year\n",
    "\n",
    "    defense_dfs.append(defense_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147550f3-0fa5-4f88-87c8-57a88e69dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenating all data frames\n",
    "passing = pd.concat(passing_dfs)\n",
    "receiving = pd.concat(receiving_dfs)\n",
    "rushing = pd.concat(rushing_dfs)\n",
    "# scrimmage = pd.concat(scrimmage_dfs)\n",
    "defense = pd.concat(defense_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60e4a4d0-46b7-4f3a-a161-1899163ee7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "passing.to_csv(\"passing.csv\")\n",
    "receiving.to_csv(\"receiving.csv\")\n",
    "rushing.to_csv(\"rushing.csv\")\n",
    "# scrimmage.to_csv(\"scrimmage.csv\")\n",
    "defense.to_csv(\"defense.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "10550208-5f24-433a-884c-f9da8ed854a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pro football references team stats reference url\n",
    "team_stats_url = \"https://www.pro-football-reference.com/years/{}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "199d0c0b-0ddc-4d2e-8d33-f42542edd52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping team stats for all years in time frame\n",
    "for year in years:\n",
    "    url = team_stats_url.format(year)\n",
    "    data = requests.get(url)\n",
    "\n",
    "    with open(\"teams/{}.html\".format(year), \"w+\", encoding=\"utf-8\") as f:\n",
    "        f.write(data.text)\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc5e9ea1-d798-4176-aa07-f9287f4562e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing team data\n",
    "team_dfs = []\n",
    "for year in years:\n",
    "    with open(\"teams/{}.html\".format(year)) as f:\n",
    "        page = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    header_rows = soup.find_all('tr', class_='thead')\n",
    "    for header_row in header_rows:\n",
    "        header_row.decompose()\n",
    "    team_table = soup.find(id=\"AFC\")\n",
    "    team_df = pd.read_html(StringIO(str(team_table)))[0]\n",
    "    team_df[\"Year\"] = year\n",
    "\n",
    "    if 'T' in team_df.columns:\n",
    "        del team_df[\"T\"] # unsure what this column does\n",
    "\n",
    "    team_dfs.append(team_df)\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    header_rows = soup.find_all('tr', class_='thead')\n",
    "    for header_row in header_rows:\n",
    "        header_row.decompose()\n",
    "    team_table = soup.find(id=\"NFC\")\n",
    "    team_df = pd.read_html(StringIO(str(team_table)))[0]\n",
    "    team_df[\"Year\"] = year\n",
    "\n",
    "    if 'T' in team_df.columns:\n",
    "        del team_df[\"T\"]\n",
    "\n",
    "    team_dfs.append(team_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "959432fc-21f3-4b4f-bfe7-9d5e773bab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "teams = pd.concat(team_dfs)\n",
    "teams.to_csv(\"teams.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
